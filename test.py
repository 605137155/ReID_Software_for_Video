

# -*- coding: utf-8 -*-

# Form implementation generated from reading ui file 'new2.ui'
#
# Created by: PyQt5 UI code generator 5.15.7
#
# WARNING: Any manual changes made to this file will be lost when pyuic5 is
# run again.  Do not edit this file unless you know what you are doing.

from PyQt5 import QtCore, QtGui, QtWidgets
import cv2
import time
import sys
import numpy as np
import copy
import os.path as osp
import os
from yolo_ReID import *
from PyQt5.QtGui import QImage, QPixmap
from PyQt5.QtWidgets import QApplication, QWidget, QMainWindow
from PyQt5.QtCore import QThread, QWaitCondition, QMutex, pyqtSignal, QObject, pyqtSlot




class Worker(QObject):
    def __init__(self, Ui_MainWindow):
        super().__init__()
        self.Ui_MainWindow = Ui_MainWindow
        self.paused = False
        print("生成了！")

    @pyqtSlot()
    def pause_function(self):
        self.paused = True

    @pyqtSlot()
    def resume_function(self):
        self.paused = False

    @pyqtSlot()
    def start_function(self):
        self.paused = False
        print("start")
        self.do_function()

    @pyqtSlot()
    def do_function(self):
        print("执行了！")
        while True:

            if not self.paused:
                self.Ui_MainWindow.inference = True
                print("开始！！！")

                # yolov5的输入大小
                INPUT_WIDTH = 640
                INPUT_HEIGHT = 640
                time1 = time.time()
                colors = [(255, 255, 0), (0, 255, 0), (0, 255, 255), (255, 0, 0)]
                is_cuda = len(sys.argv) > 1 and sys.argv[1] == "cuda"

                # 目标检测模型和reid模型
                root_path = self.Ui_MainWindow.root_path  # 项目根目录

                print(root_path)
                yolov5_path = osp.join(root_path, 'config_files', 'yolov5s.onnx')
                reid_path = osp.join(root_path, 'config_files', 'reid_resnet50.onnx')
                class_path = osp.join(root_path, 'config_files', 'classes.txt')

                net = build_model(is_cuda, yolov5_path)
                reidModule = reid_model(is_cuda, reid_path)
                class_list = load_classes(class_path)
                threshold_similarity = 0.996

                # 加载视频
                capture = load_capture(self.Ui_MainWindow.video_path)
                start = time.time_ns()
                frame_count = 0
                total_frames = 0
                fps = -1

                # 视频规格
                width = int(capture.get(cv2.CAP_PROP_FRAME_WIDTH))
                height = int(capture.get(cv2.CAP_PROP_FRAME_HEIGHT))
                print(width)
                print(height)
                fourcc = cv2.VideoWriter_fourcc(*"mp4v")
                fpss = capture.get(cv2.CAP_PROP_FPS)

                out = cv2.VideoWriter('output.mp4', fourcc, fpss, (width, height))

                # 获取target的feature
                target = cv2.imread(self.Ui_MainWindow.target_path)
                target_feature = reidFeatrueExtract(target, reidModule)
                target_feature_norm = target_feature / np.linalg.norm(target_feature)

                # 开始帧处理
                start_clock = time.time()
                print("开始帧处理")
                while self.Ui_MainWindow.inference:

                    # Frame 将获得视频中/相机中的下一帧的(通过“cap”)
                    # Ret 将从相机中获取的帧中获得返回值，要么为true，要么为false
                    _, frame = capture.read()

                    if frame is None:
                        print("End of stream")
                        break
                    # 原帧的深拷贝
                    f_old = copy.deepcopy(frame)
                    # 目标检测(行人检测)
                    inputImage = format_yolov5(frame)
                    outs = detect(inputImage, net, INPUT_WIDTH, INPUT_HEIGHT)
                    class_ids, confidences, boxes = wrap_detection(inputImage, outs[0], INPUT_WIDTH, INPUT_HEIGHT)
                    frame_count += 1
                    total_frames += 1
                    features = []
                    coordinate = []
                    # 绘制行人框，且提取所有行人特征，及其对应的帧坐标box
                    for (classid, confidence, box) in zip(class_ids, confidences, boxes):
                        # 如果是行人person的检测框，则提取该行人的特征
                        if classid == 0:
                            color = colors[int(classid) % len(colors)]
                            a = np.array(frame[box[1]:box[1] + box[3], box[0]:box[0] + box[2]])
                            if a.shape[0] <= 0 or a.shape[1] <= 0:  # 非法box过滤img
                                continue
                            f = reidFeatrueExtract(a, reidModule)
                            f_norm = f / np.linalg.norm(f)
                            cos_sim = np.dot(f_norm, target_feature_norm)

                            # 对比识别
                            if cos_sim > threshold_similarity:
                                print(cos_sim)
                                # 输出人物出现时间
                                p_clock = time.time()
                                second = int(p_clock - start_clock)
                                minute = int(second / 60)
                                print("{}分{}秒".format(minute, second))
                                # 标记任务框框
                                cv2.rectangle(frame, box, color, 2)
                                cv2.rectangle(frame, (box[0], box[1] - 20), (box[0] + box[2], box[1]), color, -1)
                                cv2.putText(frame, class_list[classid], (box[0], box[1] - 10), cv2.FONT_HERSHEY_SIMPLEX,
                                            .5,
                                            (0, 0, 0))
                            features.append(f)
                            # person对应坐标
                            coordinate.append(box)
                        else:
                            continue

                    if frame_count >= 30:
                        end = time.time()
                        fps = 1000000000 * frame_count / (end - start)
                        frame_count = 0
                        start = time.time_ns()

                    if fps > 0:
                        fps_label = "FPS: %.2f" % fps
                        cv2.putText(frame, fps_label, (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)

                    # 保存
                    out.write(frame)
                    # cv2 BGR 转 PYQT5 RBG
                    height, width, bytesPerComponent = frame.shape
                    bytesPerLine = 3 * width
                    cv2.cvtColor(frame, cv2.COLOR_BGR2RGB, frame)
                    QImg = QImage(frame.data, width, height, bytesPerLine, QImage.Format_RGB888)
                    pixmap = QPixmap.fromImage(QImg)
                    self.Ui_MainWindow.The_inference.setPixmap(pixmap)

                    if cv2.waitKey(1) > -1:
                        print("finished by user1")

                    # if self.inference:
                    #     while self.paused:
                    #         ...

                    # print(self.inference)
                    if not self.Ui_MainWindow.inference:
                        print("finished by user2")
                        break

                print("Total frames: " + str(total_frames))
                time2 = time.time()
                print("total time: " + str(time2 - time1))
                capture.release()
                out.release()
                cv2.destroyAllWindows()

            else:
                time.sleep(0.1)




class Ui_MainWindow(object):

    def __init__(self):
        super().__init__()

    def setupUi(self, MainWindow):
        MainWindow.setObjectName("MainWindow")
        # MainWindow.resize(827, 600)
        # 自适应屏幕大小的UI
        MainWindow.title = "行人重识别应用"

        # 获取显示器分辨率
        MainWindow.desktop = QApplication.desktop()
        MainWindow.screenRect = MainWindow.desktop.screenGeometry()
        MainWindow.screenheight = MainWindow.screenRect.height()
        MainWindow.screenwidth = MainWindow.screenRect.width()

        MainWindow.height = int(MainWindow.screenheight * 0.7)

        MainWindow.width = int(MainWindow.screenwidth * 0.7)

        print("Screen height {}".format(MainWindow.screenheight))
        print("Screen width {}".format(MainWindow.screenwidth))

        MainWindow.resize(MainWindow.width, MainWindow.height)
        MainWindow.wid = QWidget(MainWindow)
        MainWindow.setCentralWidget(MainWindow.wid)
        MainWindow.setWindowTitle(MainWindow.title)
        # MainWindow.initUI()

        self.centralwidget = QtWidgets.QWidget(MainWindow)
        self.centralwidget.setObjectName("centralwidget")
        # 导入图片（->,👇,长，宽）
        self.Image = QtWidgets.QPushButton(self.centralwidget)
        self.Image.setGeometry(QtCore.QRect(50, 70, 200, 100))
        self.Image.setObjectName("Image")
        self.Image.clicked.connect(self.From_files)
        # 导入视频
        self.Video = QtWidgets.QPushButton(self.centralwidget)
        self.Video.setGeometry(QtCore.QRect(50, 326, 200, 100))
        self.Video.setObjectName("Video")
        self.Video.clicked.connect(self.Load_Videl)

        # 选择模型
        self.Model = QtWidgets.QPushButton(self.centralwidget)
        self.Model.setGeometry(QtCore.QRect(50, 436, 200, 100))
        self.Model.setObjectName("Model")
        self.Model.clicked.connect(self.Load_Model)

        # ReID推理
        self.Inference = QtWidgets.QPushButton(self.centralwidget)
        self.Inference.setGeometry(QtCore.QRect(50, 556, 80, 100))
        self.Inference.setObjectName("Inference")
        self.Inference.clicked.connect(self.ReID_Inference)

        # 暂停
        self.Stop = QtWidgets.QPushButton(self.centralwidget)
        self.Stop.setGeometry(QtCore.QRect(170, 556, 80, 100))
        self.Stop.setObjectName("Stop")
        self.Stop.clicked.connect(self.Inference_Pause)

        # 唤醒
        self.Wake = QtWidgets.QPushButton(self.centralwidget)
        self.Wake.setGeometry(QtCore.QRect(170, 700, 80, 100))
        self.Wake.setObjectName("Wake")
        self.Wake.clicked.connect(self.Inference_Wake)

        # 显示的图片
        self.The_image = QtWidgets.QLabel(self.centralwidget)
        self.The_image.setGeometry(QtCore.QRect(300, 70, 168, 256))
        self.The_image.setObjectName("The_image")
        self.The_image.setFrameShape(QtWidgets.QFrame.Box)

        # 导入的视频
        self.The_video = QtWidgets.QLabel(self.centralwidget)
        self.The_video.setGeometry(QtCore.QRect(560, 70, 168, 256))
        self.The_video.setObjectName("The_video")
        self.The_video.setFrameShape(QtWidgets.QFrame.Box)

        self.The_model = QtWidgets.QLabel(self.centralwidget)
        self.The_model.setGeometry(QtCore.QRect(820, 70, 168, 256))
        self.The_model.setObjectName("The_model")

        # 推理的视频帧
        self.The_inference = QtWidgets.QLabel(self.centralwidget)
        self.The_inference.setGeometry(QtCore.QRect(300, 360, 1280, 720))
        self.The_inference.setObjectName("The_inference")
        self.The_inference.setFrameShape(QtWidgets.QFrame.Box)

        MainWindow.setCentralWidget(self.centralwidget)
        self.menubar = QtWidgets.QMenuBar(MainWindow)
        self.menubar.setGeometry(QtCore.QRect(300, 600, 827, 22))
        self.menubar.setObjectName("menubar")
        MainWindow.setMenuBar(self.menubar)
        self.statusbar = QtWidgets.QStatusBar(MainWindow)
        self.statusbar.setObjectName("statusbar")
        MainWindow.setStatusBar(self.statusbar)

        self.retranslateUi(MainWindow)
        QtCore.QMetaObject.connectSlotsByName(MainWindow)




    def From_files(self):
        # 获取当地选取图片的绝对url，并将其显示在The_image的label控件中
        the_image_url = QtWidgets.QFileDialog.getOpenFileName(None, 'select image', '', '')
        url = str(the_image_url).split("'")
        # ['(', 'C:/Users/Minghui_Zhang/Desktop/yolov5-opencv-cpp-python-main/target.jpg', ', ', 'All Files (*)', ')']
        print(url[1])
        # self.The_Url.setText(QtCore.QCoreApplication.translate("MainWindow", "路径：" + url[1]))
        img = QtGui.QPixmap(url[1])
        self.target_path = url[1]
        self.The_image.setPixmap(img)



    def Load_Videl(self):  # 加载视频的信号
        the_video_url = QtWidgets.QFileDialog.getOpenFileName(None, 'select video', '', '')
        video_url = str(the_video_url).split("'")
        # 调用yolo.py的方法加载cv2格式的视频,放入video_caputre属性
        self.video_path = video_url[1]
        self.The_video.setText("已导入视频")

    def Load_Model(self):
        # 线程控制
        self.thread = QThread()
        self.worker = Worker(self)
        self.worker.moveToThread(self.thread)
        self.thread.start()
        print("装在完毕")
        self.root_path = os.path.dirname(os.getcwd())  # 项目根目录
        print("根目录")
        print(self.root_path)

    def ReID_Inference(self):  # 推理

        self.worker.start_function()

    def Inference_Pause(self):
        self.worker.pause_function()

    def Inference_Wake(self):
        # self.inference = False
        # self.t.resume()
        self.worker.resume_function()

    def retranslateUi(self, MainWindow):
        _translate = QtCore.QCoreApplication.translate
        MainWindow.setWindowTitle(_translate("MainWindow", "MainWindow"))
        self.Image.setText(_translate("MainWindow", "导入图片"))
        self.Video.setText(_translate("MainWindow", "导入视频"))
        self.Model.setText(_translate("MainWindow", "选择模型"))
        self.Inference.setText(_translate("MainWindow", "ReID推理"))
        self.The_image.setText(_translate("MainWindow", "请导入图片"))
        self.The_video.setText(_translate("MainWindow", "请导入视频"))
        self.The_model.setText(_translate("MainWindow", "请选择模型"))
        self.The_inference.setText(_translate("MainWindow", "请推理"))
        self.Stop.setText(_translate("MainWindow", "暂停推理"))
        self.Wake.setText(_translate("MainWindow", "继续推理"))


if __name__ == '__main__':
    app = QtWidgets.QApplication(sys.argv)
    MainWindow = QtWidgets.QMainWindow()
    ui = Ui_MainWindow()
    ui.setupUi(MainWindow)
    MainWindow.show()
    sys.exit(app.exec_())